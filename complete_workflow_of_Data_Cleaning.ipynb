{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/eq5AaG7u8AOFZs0RkkK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIwithMallesh/Cleaning-Projects-for-Real-World-Science-A-Collection-of-Practical-Projects/blob/main/complete_workflow_of_Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VlR_IOYAjNTD"
      },
      "outputs": [],
      "source": [
        "# Sample Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a sample dataset with various data quality issues\n",
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    'customer_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
        "    'name': ['John Doe', 'Alice Smith', 'Bob Johnson', 'Carol Davis', 'Eve Brown',\n",
        "             'Frank Wilson', 'Grace Lee', 'HENRY MILLER', '  ivy chen  ', 'Jack Taylor'],\n",
        "    'age': [25, 32, 45, np.nan, 29, 150, 35, 41, 28, -5],\n",
        "    'email': ['john@email.com', 'alice.smith@email.com', 'bob@email.com',\n",
        "              'carol.davis@email.com', 'invalid_email', 'frank@email.com',\n",
        "              'grace.lee@email.com', 'henry@email.com', 'ivy@email.com', 'jack@email.com'],\n",
        "    'salary': [50000, 75000, 60000, 80000, 55000, 90000, 72000, 68000, 62000, 58000],\n",
        "    'join_date': ['2020-01-15', '2019-03-22', '2021-07-10', '2018-11-05',\n",
        "                  '2022-02-28', '2017-12-15', '2020-06-20', '2021-09-14',\n",
        "                  'invalid_date', '2023-01-10'],\n",
        "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
        "             'New York', 'los angeles', 'CHICAGO', 'Houston', 'Miami'],\n",
        "    'purchase_amount': [150.50, 200.75, 180.25, 300.00, 125.50,\n",
        "                       250.80, 175.25, 220.75, 190.50, 210.25],\n",
        "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'B', 'C', 'A', 'D']\n",
        "}\n",
        "\n",
        "# Create some duplicate rows by appending duplicates\n",
        "df = pd.DataFrame(data)\n",
        "duplicates = df.iloc[[0, 2, 5]].copy()\n",
        "df = pd.concat([df, duplicates], ignore_index=True)\n",
        "\n",
        "print(\" ORIGINAL DATASET (WITH ALL ISSUES):\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImiaH8f_jdNA",
        "outputId": "d9d6a0b3-e72b-4e3a-f71e-cc3bb50f61cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ORIGINAL DATASET (WITH ALL ISSUES):\n",
            "Dataset shape: (13, 9)\n",
            "\n",
            "First 10 rows:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13 entries, 0 to 12\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   customer_id      13 non-null     int64  \n",
            " 1   name             13 non-null     object \n",
            " 2   age              12 non-null     float64\n",
            " 3   email            13 non-null     object \n",
            " 4   salary           13 non-null     int64  \n",
            " 5   join_date        13 non-null     object \n",
            " 6   city             13 non-null     object \n",
            " 7   purchase_amount  13 non-null     float64\n",
            " 8   category         13 non-null     object \n",
            "dtypes: float64(2), int64(2), object(5)\n",
            "memory usage: 1.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDBBjQMxjdJm",
        "outputId": "cff985ba-6084-4a37-a9cc-1b368b2fafb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customer_id          name    age                  email  salary  \\\n",
            "0          101      John Doe   25.0         john@email.com   50000   \n",
            "1          102   Alice Smith   32.0  alice.smith@email.com   75000   \n",
            "2          103   Bob Johnson   45.0          bob@email.com   60000   \n",
            "3          104   Carol Davis    NaN  carol.davis@email.com   80000   \n",
            "4          105     Eve Brown   29.0          invalid_email   55000   \n",
            "5          106  Frank Wilson  150.0        frank@email.com   90000   \n",
            "6          107     Grace Lee   35.0    grace.lee@email.com   72000   \n",
            "7          108  HENRY MILLER   41.0        henry@email.com   68000   \n",
            "8          109    ivy chen     28.0          ivy@email.com   62000   \n",
            "9          110   Jack Taylor   -5.0         jack@email.com   58000   \n",
            "\n",
            "      join_date         city  purchase_amount category  \n",
            "0    2020-01-15     New York           150.50        A  \n",
            "1    2019-03-22  Los Angeles           200.75        B  \n",
            "2    2021-07-10      Chicago           180.25        A  \n",
            "3    2018-11-05      Houston           300.00        C  \n",
            "4    2022-02-28      Phoenix           125.50        B  \n",
            "5    2017-12-15     New York           250.80        A  \n",
            "6    2020-06-20  los angeles           175.25        B  \n",
            "7    2021-09-14      CHICAGO           220.75        C  \n",
            "8  invalid_date      Houston           190.50        A  \n",
            "9    2023-01-10        Miami           210.25        D  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Understand Your Data"
      ],
      "metadata": {
        "id": "fr6y6YSRjdGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" STEP 1: UNDERSTAND YOUR DATA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Basic information\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(f\"Total duplicate rows: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzx_bNm_jdEZ",
        "outputId": "9a7053d4-0805-41bd-a2f3-f7f52df12acc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " STEP 1: UNDERSTAND YOUR DATA\n",
            "==================================================\n",
            "Dataset Info:\n",
            "Shape: (13, 9)\n",
            "Columns: ['customer_id', 'name', 'age', 'email', 'salary', 'join_date', 'city', 'purchase_amount', 'category']\n",
            "\n",
            "Data Types:\n",
            "customer_id          int64\n",
            "name                object\n",
            "age                float64\n",
            "email               object\n",
            "salary               int64\n",
            "join_date           object\n",
            "city                object\n",
            "purchase_amount    float64\n",
            "category            object\n",
            "dtype: object\n",
            "\n",
            "Basic Statistics:\n",
            "        customer_id      name        age           email        salary  \\\n",
            "count     13.000000        13   12.00000              13     13.000000   \n",
            "unique          NaN        10        NaN              10           NaN   \n",
            "top             NaN  John Doe        NaN  john@email.com           NaN   \n",
            "freq            NaN         2        NaN               2           NaN   \n",
            "mean     105.000000       NaN   50.00000             NaN  66923.076923   \n",
            "std        2.972092       NaN   48.50492             NaN  13671.512587   \n",
            "min      101.000000       NaN   -5.00000             NaN  50000.000000   \n",
            "25%      103.000000       NaN   27.25000             NaN  58000.000000   \n",
            "50%      105.000000       NaN   33.50000             NaN  62000.000000   \n",
            "75%      107.000000       NaN   45.00000             NaN  75000.000000   \n",
            "max      110.000000       NaN  150.00000             NaN  90000.000000   \n",
            "\n",
            "         join_date      city  purchase_amount category  \n",
            "count           13        13        13.000000       13  \n",
            "unique          10         8              NaN        4  \n",
            "top     2020-01-15  New York              NaN        A  \n",
            "freq             2         4              NaN        7  \n",
            "mean           NaN       NaN       198.930769      NaN  \n",
            "std            NaN       NaN        47.972468      NaN  \n",
            "min            NaN       NaN       125.500000      NaN  \n",
            "25%            NaN       NaN       175.250000      NaN  \n",
            "50%            NaN       NaN       190.500000      NaN  \n",
            "75%            NaN       NaN       220.750000      NaN  \n",
            "max            NaN       NaN       300.000000      NaN  \n",
            "\n",
            "Missing Values:\n",
            "customer_id        0\n",
            "name               0\n",
            "age                1\n",
            "email              0\n",
            "salary             0\n",
            "join_date          0\n",
            "city               0\n",
            "purchase_amount    0\n",
            "category           0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Rows:\n",
            "Total duplicate rows: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Handle Duplicates"
      ],
      "metadata": {
        "id": "A_PLKzBojdCJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 2: HANDLE DUPLICATES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Before removing duplicates: {df.shape} rows\")\n",
        "df_cleaned = df.drop_duplicates()\n",
        "print(f\"After removing duplicates: {df_cleaned.shape} rows\")\n",
        "\n",
        "# Check for duplicates based on specific columns\n",
        "print(f\"Duplicates based on customer_id: {df_cleaned.duplicated(subset=['customer_id']).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WJhhRJPjc_k",
        "outputId": "95d18768-c54e-47aa-8fa7-fd4e27b9da5c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 2: HANDLE DUPLICATES\n",
            "==================================================\n",
            "Before removing duplicates: (13, 9) rows\n",
            "After removing duplicates: (10, 9) rows\n",
            "Duplicates based on customer_id: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Manage Missing Data"
      ],
      "metadata": {
        "id": "xSjPqc8Pjc9I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 3: MANAGE MISSING DATA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df_cleaned.isnull().sum())\n",
        "\n",
        "# Handle missing values in 'age' column (only considering 18–100 range)\n",
        "valid_age = df_cleaned.loc[(df_cleaned['age'] >= 18) & (df_cleaned['age'] <= 100), 'age']\n",
        "age_median = valid_age.median()\n",
        "\n",
        "# Fill missing or invalid age values with this median\n",
        "df_cleaned.loc[(df_cleaned['age'] < 18) | (df_cleaned['age'] > 100) | (df_cleaned['age'].isna()), 'age'] = age_median\n",
        "\n",
        "print(f\"\\nFilled missing or out-of-range age values with median (18–100): {age_median}\")\n",
        "\n",
        "\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sJ1yeMijcFE",
        "outputId": "121e5aa6-f509-4594-ae32-04588c9c04ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 3: MANAGE MISSING DATA\n",
            "==================================================\n",
            "Missing values before cleaning:\n",
            "customer_id        0\n",
            "name               0\n",
            "age                1\n",
            "email              0\n",
            "salary             0\n",
            "join_date          0\n",
            "city               0\n",
            "purchase_amount    0\n",
            "category           0\n",
            "dtype: int64\n",
            "\n",
            "Filled missing or out-of-range age values with median (18–100): 32.0\n",
            "\n",
            "Missing values after cleaning:\n",
            "customer_id        0\n",
            "name               0\n",
            "age                0\n",
            "email              0\n",
            "salary             0\n",
            "join_date          0\n",
            "city               0\n",
            "purchase_amount    0\n",
            "category           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Transform Data Types"
      ],
      "metadata": {
        "id": "HEf4v7OFpLTh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 4: TRANSFORM DATA TYPES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Data types before cleaning:\")\n",
        "print(df_cleaned.dtypes)\n",
        "\n",
        "# Convert join_date to datetime\n",
        "df_cleaned['join_date'] = pd.to_datetime(df_cleaned['join_date'], errors='coerce')\n",
        "\n",
        "print(\"\\nData types after cleaning:\")\n",
        "print(df_cleaned.dtypes)\n",
        "\n",
        "# Check for conversion issues\n",
        "print(f\"\\nRows with invalid dates: {df_cleaned['join_date'].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgSTNPkvpOb6",
        "outputId": "68f3c93b-2f9f-49ec-fe47-9694077d432b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 4: TRANSFORM DATA TYPES\n",
            "==================================================\n",
            "Data types before cleaning:\n",
            "customer_id          int64\n",
            "name                object\n",
            "age                float64\n",
            "email               object\n",
            "salary               int64\n",
            "join_date           object\n",
            "city                object\n",
            "purchase_amount    float64\n",
            "category            object\n",
            "dtype: object\n",
            "\n",
            "Data types after cleaning:\n",
            "customer_id                 int64\n",
            "name                       object\n",
            "age                       float64\n",
            "email                      object\n",
            "salary                      int64\n",
            "join_date          datetime64[ns]\n",
            "city                       object\n",
            "purchase_amount           float64\n",
            "category                   object\n",
            "dtype: object\n",
            "\n",
            "Rows with invalid dates: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4009955504.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_cleaned['join_date'] = pd.to_datetime(df_cleaned['join_date'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Clean Text Data"
      ],
      "metadata": {
        "id": "z1gu4yshp0-I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 5: CLEAN TEXT DATA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Clean name column\n",
        "print(\"Name column before cleaning:\")\n",
        "print(df_cleaned['name'].unique())\n",
        "\n",
        "df_cleaned['name'] = df_cleaned['name'].str.strip().str.title()\n",
        "print(\"\\nName column after cleaning:\")\n",
        "print(df_cleaned['name'].unique())\n",
        "\n",
        "# Clean city column (standardize casing)\n",
        "print(\"\\nCity column before cleaning:\")\n",
        "print(df_cleaned['city'].unique())\n",
        "\n",
        "df_cleaned['city'] = df_cleaned['city'].str.title()\n",
        "print(\"\\nCity column after cleaning:\")\n",
        "print(df_cleaned['city'].unique())\n",
        "\n",
        "# Validate email format\n",
        "print(\"\\nEmail validation:\")\n",
        "import re\n",
        "def is_valid_email(email):\n",
        "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "    return bool(re.match(pattern, email))\n",
        "\n",
        "df_cleaned['is_valid_email'] = df_cleaned['email'].apply(is_valid_email)\n",
        "print(f\"Valid emails: {df_cleaned['is_valid_email'].sum()}/{len(df_cleaned)}\")\n",
        "print(\"Invalid emails:\")\n",
        "print(df_cleaned[~df_cleaned['is_valid_email']]['email'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x6rGnpa8EjG",
        "outputId": "a40bbcc0-069e-4f1c-a7da-fec15fd89224"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 5: CLEAN TEXT DATA\n",
            "==================================================\n",
            "Name column before cleaning:\n",
            "['John Doe' 'Alice Smith' 'Bob Johnson' 'Carol Davis' 'Eve Brown'\n",
            " 'Frank Wilson' 'Grace Lee' 'Henry Miller' 'Ivy Chen' 'Jack Taylor']\n",
            "\n",
            "Name column after cleaning:\n",
            "['John Doe' 'Alice Smith' 'Bob Johnson' 'Carol Davis' 'Eve Brown'\n",
            " 'Frank Wilson' 'Grace Lee' 'Henry Miller' 'Ivy Chen' 'Jack Taylor']\n",
            "\n",
            "City column before cleaning:\n",
            "['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix' 'Miami']\n",
            "\n",
            "City column after cleaning:\n",
            "['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix' 'Miami']\n",
            "\n",
            "Email validation:\n",
            "Valid emails: 9/10\n",
            "Invalid emails:\n",
            "4    invalid_email\n",
            "Name: email, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6: Handle Outliers and Invalid Values"
      ],
      "metadata": {
        "id": "vP-eJ9niBvpQ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 6: HANDLE OUTLIERS AND INVALID VALUES\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Age column before cleaning:\")\n",
        "print(df_cleaned['age'].describe())\n",
        "\n",
        "# Identify and handle outliers in age (reasonable range: 18-100)\n",
        "age_outliers = df_cleaned[(df_cleaned['age'] < 18) | (df_cleaned['age'] > 100)]\n",
        "print(f\"\\nOutliers in age: {len(age_outliers)}\")\n",
        "print(age_outliers[['customer_id', 'age']])\n",
        "\n",
        "# Replace outliers with median age\n",
        "valid_age_median = df_cleaned[(df_cleaned['age'] >= 18) & (df_cleaned['age'] <= 100)]['age'].median()\n",
        "df_cleaned['age'] = np.where((df_cleaned['age'] < 18) | (df_cleaned['age'] > 100),\n",
        "                           valid_age_median, df_cleaned['age'])\n",
        "\n",
        "print(f\"\\nAge column after cleaning (outliers replaced with median: {valid_age_median}):\")\n",
        "print(df_cleaned['age'].describe())\n",
        "\n",
        "# Handle invalid dates by filling with mode (most common date)\n",
        "most_common_date = df_cleaned['join_date'].mode()[0]\n",
        "df_cleaned['join_date'] = df_cleaned['join_date'].fillna(most_common_date)\n",
        "print(f\"\\nFilled missing dates with: {most_common_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZcmJehKBy0F",
        "outputId": "4cc31590-bbc0-46d0-fc9c-f140540727e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 6: HANDLE OUTLIERS AND INVALID VALUES\n",
            "==================================================\n",
            "Age column before cleaning:\n",
            "count    10.000000\n",
            "mean     33.100000\n",
            "std       5.971227\n",
            "min      25.000000\n",
            "25%      29.750000\n",
            "50%      32.000000\n",
            "75%      34.250000\n",
            "max      45.000000\n",
            "Name: age, dtype: float64\n",
            "\n",
            "Outliers in age: 0\n",
            "Empty DataFrame\n",
            "Columns: [customer_id, age]\n",
            "Index: []\n",
            "\n",
            "Age column after cleaning (outliers replaced with median: 32.0):\n",
            "count    10.000000\n",
            "mean     33.100000\n",
            "std       5.971227\n",
            "min      25.000000\n",
            "25%      29.750000\n",
            "50%      32.000000\n",
            "75%      34.250000\n",
            "max      45.000000\n",
            "Name: age, dtype: float64\n",
            "\n",
            "Filled missing dates with: 2017-12-15 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Data Validation and Final Checks"
      ],
      "metadata": {
        "id": "OyURQ7U9B0RG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n STEP 7: DATA VALIDATION AND FINAL CHECKS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create data quality summary\n",
        "def data_quality_report(df):\n",
        "    report = pd.DataFrame({\n",
        "        'column': df.columns,\n",
        "        'data_type': df.dtypes.values,\n",
        "        'non_null_count': df.count().values,\n",
        "        'null_count': df.isnull().sum().values,\n",
        "        'null_percentage': (df.isnull().sum() / len(df) * 100).values,\n",
        "        'unique_count': df.nunique().values\n",
        "    })\n",
        "    return report\n",
        "\n",
        "print(\"Final Data Quality Report:\")\n",
        "quality_report = data_quality_report(df_cleaned)\n",
        "print(quality_report)\n",
        "\n",
        "# Validate data ranges\n",
        "print(\"\\nData Range Validation:\")\n",
        "print(f\"Age range: {df_cleaned['age'].min()} - {df_cleaned['age'].max()}\")\n",
        "print(f\"Salary range: ${df_cleaned['salary'].min():,} - ${df_cleaned['salary'].max():,}\")\n",
        "print(f\"Join date range: {df_cleaned['join_date'].min()} - {df_cleaned['join_date'].max()}\")\n",
        "\n",
        "# Check for consistency in categorical data\n",
        "print(\"\\nCategorical Data Summary:\")\n",
        "print(\"Categories:\", df_cleaned['category'].unique())\n",
        "print(\"Cities:\", df_cleaned['city'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wvIO40vB5JG",
        "outputId": "f33e1ef4-fc1b-4eb4-c6ad-155c368f6431"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STEP 7: DATA VALIDATION AND FINAL CHECKS\n",
            "==================================================\n",
            "Final Data Quality Report:\n",
            "            column       data_type  non_null_count  null_count  \\\n",
            "0      customer_id           int64              10           0   \n",
            "1             name          object              10           0   \n",
            "2              age         float64              10           0   \n",
            "3            email          object              10           0   \n",
            "4           salary           int64              10           0   \n",
            "5        join_date  datetime64[ns]              10           0   \n",
            "6             city          object              10           0   \n",
            "7  purchase_amount         float64              10           0   \n",
            "8         category          object              10           0   \n",
            "9   is_valid_email            bool              10           0   \n",
            "\n",
            "   null_percentage  unique_count  \n",
            "0              0.0            10  \n",
            "1              0.0            10  \n",
            "2              0.0             7  \n",
            "3              0.0            10  \n",
            "4              0.0            10  \n",
            "5              0.0             9  \n",
            "6              0.0             6  \n",
            "7              0.0            10  \n",
            "8              0.0             4  \n",
            "9              0.0             2  \n",
            "\n",
            "Data Range Validation:\n",
            "Age range: 25.0 - 45.0\n",
            "Salary range: $50,000 - $90,000\n",
            "Join date range: 2017-12-15 00:00:00 - 2023-01-10 00:00:00\n",
            "\n",
            "Categorical Data Summary:\n",
            "Categories: ['A' 'B' 'C' 'D']\n",
            "Cities: ['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix' 'Miami']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8: Final Cleaned Dataset"
      ],
      "metadata": {
        "id": "9j4HsG7SB6it"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n FINAL CLEANED DATASET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Final dataset shape: {df_cleaned.shape}\")\n",
        "print(\"\\nFirst few rows of cleaned data:\")\n",
        "print(df_cleaned.head(10))\n",
        "\n",
        "print(\"\\nDataset info:\")\n",
        "print(df_cleaned.info())\n",
        "\n",
        "# Save cleaned dataset\n",
        "df_cleaned.to_csv('cleaned_customer_data.csv', index=False)\n",
        "print(\"\\n Cleaned dataset saved as 'cleaned_customer_data.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcMgI7oBB-Wt",
        "outputId": "f2772219-8bec-4399-a3e0-9b0718e59036"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FINAL CLEANED DATASET\n",
            "==================================================\n",
            "Final dataset shape: (10, 10)\n",
            "\n",
            "First few rows of cleaned data:\n",
            "   customer_id          name   age                  email  salary  join_date  \\\n",
            "0          101      John Doe  25.0         john@email.com   50000 2020-01-15   \n",
            "1          102   Alice Smith  32.0  alice.smith@email.com   75000 2019-03-22   \n",
            "2          103   Bob Johnson  45.0          bob@email.com   60000 2021-07-10   \n",
            "3          104   Carol Davis  32.0  carol.davis@email.com   80000 2018-11-05   \n",
            "4          105     Eve Brown  29.0          invalid_email   55000 2022-02-28   \n",
            "5          106  Frank Wilson  32.0        frank@email.com   90000 2017-12-15   \n",
            "6          107     Grace Lee  35.0    grace.lee@email.com   72000 2020-06-20   \n",
            "7          108  Henry Miller  41.0        henry@email.com   68000 2021-09-14   \n",
            "8          109      Ivy Chen  28.0          ivy@email.com   62000 2017-12-15   \n",
            "9          110   Jack Taylor  32.0         jack@email.com   58000 2023-01-10   \n",
            "\n",
            "          city  purchase_amount category  is_valid_email  \n",
            "0     New York           150.50        A            True  \n",
            "1  Los Angeles           200.75        B            True  \n",
            "2      Chicago           180.25        A            True  \n",
            "3      Houston           300.00        C            True  \n",
            "4      Phoenix           125.50        B           False  \n",
            "5     New York           250.80        A            True  \n",
            "6  Los Angeles           175.25        B            True  \n",
            "7      Chicago           220.75        C            True  \n",
            "8      Houston           190.50        A            True  \n",
            "9        Miami           210.25        D            True  \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 10 entries, 0 to 9\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype         \n",
            "---  ------           --------------  -----         \n",
            " 0   customer_id      10 non-null     int64         \n",
            " 1   name             10 non-null     object        \n",
            " 2   age              10 non-null     float64       \n",
            " 3   email            10 non-null     object        \n",
            " 4   salary           10 non-null     int64         \n",
            " 5   join_date        10 non-null     datetime64[ns]\n",
            " 6   city             10 non-null     object        \n",
            " 7   purchase_amount  10 non-null     float64       \n",
            " 8   category         10 non-null     object        \n",
            " 9   is_valid_email   10 non-null     bool          \n",
            "dtypes: bool(1), datetime64[ns](1), float64(2), int64(2), object(4)\n",
            "memory usage: 810.0+ bytes\n",
            "None\n",
            "\n",
            " Cleaned dataset saved as 'cleaned_customer_data.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 9: Summary of Changes Made"
      ],
      "metadata": {
        "id": "CBR6_lAlCAcu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n SUMMARY OF DATA CLEANING ACTIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "cleaning_summary = {\n",
        "    \"Action\": [\n",
        "        \"Removed duplicate rows\",\n",
        "        \"Handled missing age values\",\n",
        "        \"Fixed invalid dates\",\n",
        "        \"Cleaned text formatting (names, cities)\",\n",
        "        \"Handled age outliers\",\n",
        "        \"Validated email formats\",\n",
        "        \"Standardized data types\"\n",
        "    ],\n",
        "    \"Details\": [\n",
        "        f\"Removed {len(df) - len(df_cleaned)} duplicate rows\",\n",
        "        f\"Filled {df['age'].isnull().sum()} missing values with median\",\n",
        "        f\"Fixed {df_cleaned['join_date'].isnull().sum()} invalid dates\",\n",
        "        \"Standardized text to title case and removed whitespace\",\n",
        "        f\"Fixed {len(age_outliers)} invalid age values\",\n",
        "        f\"Found {len(df_cleaned) - df_cleaned['is_valid_email'].sum()} invalid emails\",\n",
        "        \"Converted dates to proper datetime format\"\n",
        "    ],\n",
        "    \"Rows Affected\": [\n",
        "        len(df) - len(df_cleaned),\n",
        "        df['age'].isnull().sum(),\n",
        "        df_cleaned['join_date'].isnull().sum(),\n",
        "        \"All text columns\",\n",
        "        len(age_outliers),\n",
        "        len(df_cleaned) - df_cleaned['is_valid_email'].sum(),\n",
        "        \"All date columns\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(cleaning_summary)\n",
        "print(summary_df)\n",
        "\n",
        "print(f\"\\n Data quality improved from {len(df)} problematic rows to {len(df_cleaned)} clean rows!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GH6etn5CDp9",
        "outputId": "2cc2edf2-01f5-477f-c532-a29a1fe153aa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " SUMMARY OF DATA CLEANING ACTIONS\n",
            "==================================================\n",
            "                                    Action  \\\n",
            "0                   Removed duplicate rows   \n",
            "1               Handled missing age values   \n",
            "2                      Fixed invalid dates   \n",
            "3  Cleaned text formatting (names, cities)   \n",
            "4                     Handled age outliers   \n",
            "5                  Validated email formats   \n",
            "6                  Standardized data types   \n",
            "\n",
            "                                             Details     Rows Affected  \n",
            "0                           Removed 3 duplicate rows                 3  \n",
            "1                Filled 1 missing values with median                 1  \n",
            "2                              Fixed 0 invalid dates                 0  \n",
            "3  Standardized text to title case and removed wh...  All text columns  \n",
            "4                         Fixed 0 invalid age values                 0  \n",
            "5                             Found 1 invalid emails                 1  \n",
            "6          Converted dates to proper datetime format  All date columns  \n",
            "\n",
            " Data quality improved from 13 problematic rows to 10 clean rows!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RJHemk0CFUL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}